{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os, time, gc, random, pickle\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import requests, shutil\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t\t (113783, 4)\n",
      "Validation:\t (22255, 4)\n",
      "Test:\t\t (22391, 4)\n",
      "\n",
      "Train Landmarks:\t 14943\n",
      "Validation Landmarks:\t 7674\n",
      "Test Landmarks:\t\t 14436\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./data/triplet/train.csv')\n",
    "val_df = pd.read_csv('./data/triplet/validation.csv')\n",
    "test_df = pd.read_csv('./data/triplet/test.csv')\n",
    "\n",
    "print('Train:\\t\\t', train_df.shape)\n",
    "print('Validation:\\t', val_df.shape)\n",
    "print('Test:\\t\\t', test_df.shape)\n",
    "\n",
    "print('\\nTrain Landmarks:\\t', len(train_df['landmark_id'].unique()))\n",
    "print('Validation Landmarks:\\t', len(val_df['landmark_id'].unique()))\n",
    "print('Test Landmarks:\\t\\t', len(test_df['landmark_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>465272</td>\n",
       "      <td>a2ccf8ed2e969f6a</td>\n",
       "      <td>https://lh4.googleusercontent.com/-TPHkS5gzvm4...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64516</td>\n",
       "      <td>e205ca7c8dd7c027</td>\n",
       "      <td>https://lh3.googleusercontent.com/-V3RjsZtGpxE...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928409</td>\n",
       "      <td>4e8ab93c1620e8a3</td>\n",
       "      <td>http://mw2.google.com/mw-panoramio/photos/medi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88809</td>\n",
       "      <td>896bf928214d1ca4</td>\n",
       "      <td>http://lh5.ggpht.com/-Cy0l41uUaGA/R--yB8vy41I/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001133</td>\n",
       "      <td>375d2a153bdca926</td>\n",
       "      <td>http://lh6.ggpht.com/-UqzFpnqE9bU/S_0u1RovfdI/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                id  \\\n",
       "0    465272  a2ccf8ed2e969f6a   \n",
       "1     64516  e205ca7c8dd7c027   \n",
       "2    928409  4e8ab93c1620e8a3   \n",
       "3     88809  896bf928214d1ca4   \n",
       "4   1001133  375d2a153bdca926   \n",
       "\n",
       "                                                 url  landmark_id  \n",
       "0  https://lh4.googleusercontent.com/-TPHkS5gzvm4...            0  \n",
       "1  https://lh3.googleusercontent.com/-V3RjsZtGpxE...            0  \n",
       "2  http://mw2.google.com/mw-panoramio/photos/medi...            0  \n",
       "3  http://lh5.ggpht.com/-Cy0l41uUaGA/R--yB8vy41I/...            0  \n",
       "4  http://lh6.ggpht.com/-UqzFpnqE9bU/S_0u1RovfdI/...            0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set triplet generator\n",
    "def train_triplet_generator(df, batch_size=100, img_size=(224, 224), seed=42, \n",
    "                            prefix='./data/triplet/train/'):\n",
    "    \"\"\" training set triplet generator\n",
    "        it will generate 7400 triplet images in total\n",
    "    \"\"\"\n",
    "    # get images with only one training image landmark id and the rest landmark ids\n",
    "    np.random.seed(seed)\n",
    "    grouped = df[['landmark_id', 'image_id']].groupby('landmark_id').count().reset_index()\n",
    "    unique_neg_ids = list(grouped[grouped['image_id'] == 1]['landmark_id'].values)\n",
    "    rest_ids = list(grouped[grouped['image_id'] > 1]['landmark_id'].values)\n",
    "    size = 7400 * 2 - len(unique_neg_ids) \n",
    "    zeros = np.zeros((batch_size, 3, 1), dtype=K.floatx())\n",
    "    \n",
    "    while True:\n",
    "        # get positive and negative image landmark ids\n",
    "        np.random.shuffle(rest_ids)\n",
    "        candidate_ids = list(np.random.choice(rest_ids, size=size, replace=False))\n",
    "        pos_landmark_ids = candidate_ids[:7400]\n",
    "        neg_landmark_ids = candidate_ids[7400:] + unique_neg_ids\n",
    "        np.random.shuffle(neg_landmark_ids)\n",
    "        \n",
    "        # transform landmark id into image id\n",
    "        anc_img_ids = []\n",
    "        pos_img_ids = []\n",
    "        neg_img_ids = []\n",
    "        \n",
    "        for i in range(len(pos_landmark_ids)):\n",
    "            tmp_pos_ids = df[df['landmark_id'] == pos_landmark_ids[i]]['image_id'].values\n",
    "            anc_img_ids.append(tmp_pos_ids[0])\n",
    "            pos_img_ids.append(tmp_pos_ids[1])\n",
    "            \n",
    "            tmp_neg_ids = df[df['landmark_id'] == neg_landmark_ids[i]]['image_id'].values\n",
    "            neg_img_ids.append(tmp_neg_ids[0])\n",
    "        \n",
    "        # iterator to read batch images\n",
    "        for j in range(len(pos_img_ids) // batch_size):\n",
    "            batch_anc_img_ids = anc_img_ids[j * batch_size: (j + 1) * batch_size]\n",
    "            batch_pos_img_ids = pos_img_ids[j * batch_size: (j + 1) * batch_size]\n",
    "            batch_neg_img_ids = neg_img_ids[j * batch_size: (j + 1) * batch_size]\n",
    "            \n",
    "            # get images\n",
    "            anc_imgs = []\n",
    "            pos_imgs = []\n",
    "            neg_imgs = []\n",
    "            \n",
    "            # iteratively read images\n",
    "            for k in range(batch_size):\n",
    "                anc_path = prefix + str(batch_anc_img_ids[k]) + '.jpg'\n",
    "                pos_path = prefix + str(batch_pos_img_ids[k]) + '.jpg'\n",
    "                neg_path = prefix + str(batch_neg_img_ids[k]) + '.jpg'\n",
    "                \n",
    "                tmp_anc_img = load_img(anc_path, target_size=img_size)\n",
    "                tmp_anc_img = img_to_array(tmp_anc_img)\n",
    "                anc_imgs.append(tmp_anc_img)\n",
    "                \n",
    "                tmp_pos_img = load_img(pos_path, target_size=img_size)\n",
    "                tmp_pos_img = img_to_array(tmp_pos_img)\n",
    "                pos_imgs.append(tmp_pos_img)\n",
    "                \n",
    "                tmp_neg_img = load_img(neg_path, target_size=img_size)\n",
    "                tmp_neg_img = img_to_array(tmp_neg_img)\n",
    "                neg_imgs.append(tmp_neg_img)\n",
    "        \n",
    "            # transform list to array\n",
    "            anc_imgs = np.array(anc_imgs, dtype=K.floatx()) / 255.0\n",
    "            pos_imgs = np.array(pos_imgs, dtype=K.floatx()) / 255.0\n",
    "            neg_imgs = np.array(neg_imgs, dtype=K.floatx()) / 255.0\n",
    "\n",
    "            yield [anc_imgs, pos_imgs, neg_imgs], zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation set triplet generator\n",
    "def val_triplet_generator(df, batch_size=128, img_size=(224, 224), \n",
    "                          seed=42, prefix='./data/triplet/validation'):\n",
    "    \"\"\" validation set triplet collector \"\"\"\n",
    "    \n",
    "     # get images with only one image landmark id and the rest landmark ids\n",
    "    grouped = df[['landmark_id', 'image_id']].groupby('landmark_id').count().reset_index()\n",
    "    unique_neg_ids = list(grouped[grouped['image_id'] == 1]['landmark_id'].values)\n",
    "    rest_ids = list(grouped[grouped['image_id'] > 1]['landmark_id'].values)\n",
    "    size = 3072 * 2 - len(unique_neg_ids) \n",
    "    zeros = np.zeros((batch_size, 3, 1), dtype=K.floatx())\n",
    "    \n",
    "    while True:\n",
    "        # get positive and negative image landmark ids\n",
    "        np.random.seed(seed)\n",
    "        candidate_ids = list(np.random.choice(rest_ids, size=size, replace=False))\n",
    "        pos_landmark_ids = candidate_ids[:3072]\n",
    "        neg_landmark_ids = candidate_ids[3072:] + unique_neg_ids\n",
    "        np.random.shuffle(neg_landmark_ids)\n",
    "        \n",
    "        # transform landmark id into image id\n",
    "        anc_img_ids = []\n",
    "        pos_img_ids = []\n",
    "        neg_img_ids = []\n",
    "        \n",
    "        for i in range(len(pos_landmark_ids)):\n",
    "            tmp_pos_ids = df[df['landmark_id'] == pos_landmark_ids[i]]['image_id'].values\n",
    "            anc_img_ids.append(tmp_pos_ids[0])\n",
    "            pos_img_ids.append(tmp_pos_ids[1])\n",
    "            \n",
    "            tmp_neg_ids = df[df['landmark_id'] == neg_landmark_ids[i]]['image_id'].values\n",
    "            neg_img_ids.append(tmp_neg_ids[0])\n",
    "        \n",
    "        # iterator to read batch images\n",
    "        for j in range(len(pos_img_ids) // batch_size):\n",
    "            batch_anc_img_ids = anc_img_ids[j * batch_size: (j + 1) * batch_size]\n",
    "            batch_pos_img_ids = pos_img_ids[j * batch_size: (j + 1) * batch_size]\n",
    "            batch_neg_img_ids = neg_img_ids[j * batch_size: (j + 1) * batch_size]\n",
    "            \n",
    "            # get images\n",
    "            anc_imgs = []\n",
    "            pos_imgs = []\n",
    "            neg_imgs = []\n",
    "            \n",
    "            # iteratively read images\n",
    "            for k in range(batch_size):\n",
    "                anc_path = prefix + str(batch_anc_img_ids[k]) + '.jpg'\n",
    "                pos_path = prefix + str(batch_pos_img_ids[k]) + '.jpg'\n",
    "                neg_path = prefix + str(batch_neg_img_ids[k]) + '.jpg'\n",
    "                \n",
    "                tmp_anc_img = load_img(anc_path, target_size=img_size)\n",
    "                tmp_anc_img = img_to_array(tmp_anc_img)\n",
    "                anc_imgs.append(tmp_anc_img)\n",
    "                \n",
    "                tmp_pos_img = load_img(pos_path, target_size=img_size)\n",
    "                tmp_pos_img = img_to_array(tmp_pos_img)\n",
    "                pos_imgs.append(tmp_pos_img)\n",
    "                \n",
    "                tmp_neg_img = load_img(neg_path, target_size=img_size)\n",
    "                tmp_neg_img = img_to_array(tmp_neg_img)\n",
    "                neg_imgs.append(tmp_neg_img)\n",
    "        \n",
    "            # transform list to array\n",
    "            anc_imgs = np.array(anc_imgs, dtype=K.floatx()) / 255.0\n",
    "            pos_imgs = np.array(pos_imgs, dtype=K.floatx()) / 255.0\n",
    "            neg_imgs = np.array(neg_imgs, dtype=K.floatx()) / 255.0\n",
    "            \n",
    "            yield [anc_imgs, pos_imgs, neg_imgs], zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Triplet Loss Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base network for triplet network\n",
    "def base_net(input_shape=(224, 224, 3)):\n",
    "    \"\"\" define triplet network \"\"\"\n",
    "    # load pre-trained VGG16 model\n",
    "    vgg16 = VGG16(include_top=False, weights='imagenet', input_shape=input_shape, pooling='avg')\n",
    "    \n",
    "    # frozen shallow layers\n",
    "    vgg16.trainable = True\n",
    "    \n",
    "    set_trainable = False\n",
    "    for layer in vgg16.layers:\n",
    "        if layer.name == 'block5_conv1':\n",
    "            set_trainable = True\n",
    "        if set_trainable:\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "    \n",
    "    # define sequential model\n",
    "    model = Sequential(name='base_net')\n",
    "    model.add(vgg16)\n",
    "    model.add(Lambda(lambda x: K.l2_normalize(x, axis=1), name='l2_norm'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define triplet network\n",
    "def triplet_net(base_model, input_shape=(224, 224, 3)):\n",
    "    \"\"\" function to define triplet networks \"\"\"\n",
    "    # define input: anchor, positive, negative\n",
    "    anchor = Input(shape=input_shape, name='anchor_input')\n",
    "    positive = Input(shape=input_shape, name='positive_input')\n",
    "    negative = Input(shape=input_shape, name='negative_input')\n",
    "    \n",
    "    # extract vector represent using CNN based model\n",
    "    anc_vec = base_model(anchor)\n",
    "    pos_vec = base_model(positive)\n",
    "    neg_vec = base_model(negative)\n",
    "    \n",
    "    # stack outputs\n",
    "    stacks = Lambda(lambda x: K.stack(x, axis=1), name='output')([anc_vec, pos_vec, neg_vec])\n",
    "\n",
    "    # define inputs and outputs\n",
    "    inputs=[anchor, positive, negative]\n",
    "    outputs = stacks\n",
    "    \n",
    "    # define the triplet model\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='triplet_net')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define triplet loss\n",
    "def triplet_loss(y_true, y_pred):\n",
    "    \"\"\" function to compute triplet loss\n",
    "        margin is predefined coded, manually change if needed\n",
    "    \"\"\"\n",
    "    # define triplet margin\n",
    "    margin = K.constant(0.5)\n",
    "    zero = K.constant(0.0)\n",
    "    \n",
    "    # get the prediction vector\n",
    "    anchor, positive, negative = y_pred[:, 0], y_pred[:, 1], y_pred[:, 2]\n",
    "    \n",
    "    # compute distance\n",
    "    pos_distance = K.sum(K.square(anchor - positive), axis=1)\n",
    "    neg_distance = K.sum(K.square(anchor - negative), axis=1)\n",
    "    \n",
    "    # compute loss\n",
    "    partial_loss = pos_distance - neg_distance + margin\n",
    "    full_loss = K.sum(K.maximum(partial_loss, zero), axis=0)\n",
    "    \n",
    "    return full_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Triplet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproduciable purpose\n",
    "seed = 42\n",
    "K.clear_session()\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "tf.set_random_seed(seed)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "# Define Parameters\n",
    "img_size = (224, 224, 3)  # target image size\n",
    "\n",
    "# triplet image generator\n",
    "train_generator = train_triplet_generator(train_df, batch_size=100, img_size=img_size[:2], \n",
    "                                          seed=42, prefix='./data/triplet/train/')\n",
    "\n",
    "val_generator = val_triplet_generator(val_df, batch_size=64, img_size=img_size[:2], \n",
    "                                      seed=42, prefix='./data/triplet/validation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3148: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "l2_norm (Lambda)             (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 7,079,424\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define triplet network model\n",
    "base_model = base_net(input_shape=img_size)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "base_net (Sequential)           (None, 512)          14714688    anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output (Lambda)                 (None, 3, 512)       0           base_net[1][0]                   \n",
      "                                                                 base_net[2][0]                   \n",
      "                                                                 base_net[3][0]                   \n",
      "==================================================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 7,079,424\n",
      "Non-trainable params: 7,635,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "triplet_model = triplet_net(base_model=base_model, input_shape=img_size)\n",
    "triplet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Triplet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n"
     ]
    }
   ],
   "source": [
    "# define learning scheduler\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\" Learning rate schedule \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 80:\n",
    "        lr *= 2e-1\n",
    "    elif epoch > 60:\n",
    "        lr *= 4e-1\n",
    "    elif epoch > 40:\n",
    "        lr *= 6e-1\n",
    "    elif epoch > 20:\n",
    "        lr *= 8e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "# define optimizer\n",
    "opt = keras.optimizers.Adam(lr=lr_schedule(0))\n",
    "\n",
    "# Create call backs\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "callbacks = [lr_reducer, lr_scheduler]\n",
    "\n",
    "# compile the model\n",
    "triplet_model.compile(optimizer=opt, loss=triplet_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Learning rate:  0.001\n",
      " - 76s - loss: 23.0174 - val_loss: 12.4054\n",
      "Epoch 2/100\n",
      "Learning rate:  0.001\n",
      " - 58s - loss: 14.9368 - val_loss: 9.6615\n",
      "Epoch 3/100\n",
      "Learning rate:  0.001\n",
      " - 58s - loss: 13.6975 - val_loss: 8.9605\n",
      "Epoch 4/100\n",
      "Learning rate:  0.001\n",
      " - 60s - loss: 11.9849 - val_loss: 8.8248\n",
      "Epoch 5/100\n",
      "Learning rate:  0.001\n",
      " - 59s - loss: 10.8249 - val_loss: 7.7952\n",
      "Epoch 6/100\n",
      "Learning rate:  0.001\n",
      " - 59s - loss: 10.0495 - val_loss: 7.2362\n",
      "Epoch 7/100\n",
      "Learning rate:  0.001\n",
      " - 58s - loss: 9.4097 - val_loss: 7.3948\n",
      "Epoch 8/100\n",
      "Learning rate:  0.001\n",
      " - 59s - loss: 9.3204 - val_loss: 7.5314\n",
      "Epoch 9/100\n",
      "Learning rate:  0.001\n",
      " - 59s - loss: 8.5491 - val_loss: 7.2479\n",
      "Epoch 10/100\n",
      "Learning rate:  0.001\n",
      " - 59s - loss: 8.2823 - val_loss: 6.8891\n",
      "Epoch 11/100\n",
      "Learning rate:  0.001\n",
      " - 59s - loss: 8.2587 - val_loss: 7.0462\n",
      "Epoch 12/100\n",
      "Learning rate:  0.001\n",
      " - 59s - loss: 7.5063 - val_loss: 6.7227\n",
      "Epoch 13/100\n",
      "Learning rate:  0.001\n",
      " - 59s - loss: 7.0512 - val_loss: 6.1815\n",
      "Epoch 14/100\n",
      "Learning rate:  0.001\n",
      " - 59s - loss: 6.6428 - val_loss: 6.5593\n",
      "Epoch 15/100\n",
      "Learning rate:  0.001\n",
      " - 59s - loss: 6.6093 - val_loss: 5.9779\n",
      "Epoch 16/100\n",
      "Learning rate:  0.001\n",
      " - 59s - loss: 6.3365 - val_loss: 6.1342\n",
      "Epoch 17/100\n",
      "Learning rate:  0.001\n",
      " - 59s - loss: 6.1282 - val_loss: 5.8756\n",
      "Epoch 18/100\n",
      "Learning rate:  0.001\n",
      " - 59s - loss: 5.9875 - val_loss: 5.7804\n",
      "Epoch 19/100\n",
      "Learning rate:  0.001\n",
      " - 59s - loss: 5.2881 - val_loss: 5.5033\n",
      "Epoch 20/100\n",
      "Learning rate:  0.001\n",
      " - 59s - loss: 5.3926 - val_loss: 5.3125\n",
      "Epoch 21/100\n",
      "Learning rate:  0.001\n",
      " - 60s - loss: 5.4504 - val_loss: 5.6151\n",
      "Epoch 22/100\n",
      "Learning rate:  0.0008\n",
      " - 59s - loss: 5.4927 - val_loss: 5.5066\n",
      "Epoch 23/100\n",
      "Learning rate:  0.0008\n",
      " - 59s - loss: 4.7809 - val_loss: 5.0780\n",
      "Epoch 24/100\n",
      "Learning rate:  0.0008\n",
      " - 59s - loss: 4.6675 - val_loss: 5.2107\n",
      "Epoch 25/100\n",
      "Learning rate:  0.0008\n",
      " - 59s - loss: 4.8180 - val_loss: 5.0559\n",
      "Epoch 26/100\n",
      "Learning rate:  0.0008\n",
      " - 59s - loss: 4.2974 - val_loss: 5.3996\n",
      "Epoch 27/100\n",
      "Learning rate:  0.0008\n",
      " - 59s - loss: 4.3215 - val_loss: 4.9470\n",
      "Epoch 28/100\n",
      "Learning rate:  0.0008\n",
      " - 59s - loss: 4.4359 - val_loss: 5.1021\n",
      "Epoch 29/100\n",
      "Learning rate:  0.0008\n",
      " - 59s - loss: 4.0104 - val_loss: 5.2798\n",
      "Epoch 30/100\n",
      "Learning rate:  0.0008\n",
      " - 59s - loss: 4.1820 - val_loss: 4.7938\n",
      "Epoch 31/100\n",
      "Learning rate:  0.0008\n",
      " - 59s - loss: 3.8278 - val_loss: 5.0342\n",
      "Epoch 32/100\n",
      "Learning rate:  0.0008\n",
      " - 59s - loss: 3.7706 - val_loss: 4.8235\n",
      "Epoch 33/100\n",
      "Learning rate:  0.0008\n",
      " - 59s - loss: 3.8874 - val_loss: 4.8575\n",
      "Epoch 34/100\n",
      "Learning rate:  0.0008\n",
      " - 59s - loss: 3.6054 - val_loss: 4.6704\n",
      "Epoch 35/100\n",
      "Learning rate:  0.0008\n",
      " - 59s - loss: 3.5937 - val_loss: 4.6458\n",
      "Epoch 36/100\n",
      "Learning rate:  0.0008\n",
      " - 59s - loss: 3.7411 - val_loss: 4.6834\n",
      "Epoch 37/100\n",
      "Learning rate:  0.0008\n",
      " - 59s - loss: 3.5439 - val_loss: 4.5937\n",
      "Epoch 38/100\n",
      "Learning rate:  0.0008\n",
      " - 59s - loss: 3.5428 - val_loss: 5.1449\n",
      "Epoch 39/100\n",
      "Learning rate:  0.0008\n",
      " - 59s - loss: 3.5728 - val_loss: 5.0434\n",
      "Epoch 40/100\n",
      "Learning rate:  0.0008\n",
      " - 59s - loss: 3.1726 - val_loss: 4.8424\n",
      "Epoch 41/100\n",
      "Learning rate:  0.0008\n",
      " - 59s - loss: 3.1144 - val_loss: 4.8549\n",
      "Epoch 42/100\n",
      "Learning rate:  0.0006\n",
      " - 59s - loss: 2.7070 - val_loss: 4.5701\n",
      "Epoch 43/100\n",
      "Learning rate:  0.0006\n",
      " - 59s - loss: 2.7892 - val_loss: 4.7367\n",
      "Epoch 44/100\n",
      "Learning rate:  0.0006\n",
      " - 59s - loss: 2.7225 - val_loss: 4.9027\n",
      "Epoch 45/100\n",
      "Learning rate:  0.0006\n",
      " - 59s - loss: 2.9132 - val_loss: 4.6449\n",
      "Epoch 46/100\n",
      "Learning rate:  0.0006\n",
      " - 59s - loss: 2.4055 - val_loss: 4.4338\n",
      "Epoch 47/100\n",
      "Learning rate:  0.0006\n",
      " - 59s - loss: 2.3262 - val_loss: 4.4270\n",
      "Epoch 48/100\n",
      "Learning rate:  0.0006\n",
      " - 59s - loss: 2.3554 - val_loss: 4.8007\n",
      "Epoch 49/100\n",
      "Learning rate:  0.0006\n",
      " - 59s - loss: 2.7432 - val_loss: 4.5607\n",
      "Epoch 50/100\n",
      "Learning rate:  0.0006\n",
      " - 59s - loss: 2.2576 - val_loss: 4.5687\n",
      "Epoch 51/100\n",
      "Learning rate:  0.0006\n",
      " - 59s - loss: 2.2935 - val_loss: 4.5341\n",
      "Epoch 52/100\n",
      "Learning rate:  0.0006\n",
      " - 59s - loss: 2.4911 - val_loss: 4.6831\n",
      "Epoch 53/100\n",
      "Learning rate:  0.0006\n",
      " - 59s - loss: 2.2269 - val_loss: 4.5481\n",
      "Epoch 54/100\n",
      "Learning rate:  0.0006\n",
      " - 59s - loss: 2.0513 - val_loss: 4.4422\n",
      "Epoch 55/100\n",
      "Learning rate:  0.0006\n",
      " - 59s - loss: 2.1320 - val_loss: 4.5270\n",
      "Epoch 56/100\n",
      "Learning rate:  0.0006\n",
      " - 59s - loss: 2.0926 - val_loss: 4.4916\n",
      "Epoch 57/100\n",
      "Learning rate:  0.0006\n",
      " - 59s - loss: 2.0728 - val_loss: 4.3651\n",
      "Epoch 58/100\n",
      "Learning rate:  0.0006\n",
      " - 59s - loss: 1.9511 - val_loss: 4.5003\n",
      "Epoch 59/100\n",
      "Learning rate:  0.0006\n",
      " - 59s - loss: 2.1120 - val_loss: 4.3899\n",
      "Epoch 60/100\n",
      "Learning rate:  0.0006\n",
      " - 59s - loss: 1.9035 - val_loss: 4.7287\n",
      "Epoch 61/100\n",
      "Learning rate:  0.0006\n",
      " - 59s - loss: 1.8724 - val_loss: 4.6547\n",
      "Epoch 62/100\n",
      "Learning rate:  0.0004\n",
      " - 59s - loss: 1.7598 - val_loss: 4.3671\n",
      "Epoch 63/100\n",
      "Learning rate:  0.0004\n",
      " - 59s - loss: 1.6824 - val_loss: 4.4926\n",
      "Epoch 64/100\n",
      "Learning rate:  0.0004\n",
      " - 59s - loss: 1.7171 - val_loss: 4.4214\n",
      "Epoch 65/100\n",
      "Learning rate:  0.0004\n",
      " - 59s - loss: 1.6006 - val_loss: 4.5295\n",
      "Epoch 66/100\n",
      "Learning rate:  0.0004\n",
      " - 59s - loss: 1.5876 - val_loss: 4.5259\n",
      "Epoch 67/100\n",
      "Learning rate:  0.0004\n",
      " - 59s - loss: 1.5430 - val_loss: 4.3288\n",
      "Epoch 68/100\n",
      "Learning rate:  0.0004\n",
      " - 59s - loss: 1.5501 - val_loss: 4.4306\n",
      "Epoch 69/100\n",
      "Learning rate:  0.0004\n",
      " - 59s - loss: 1.4417 - val_loss: 4.5749\n",
      "Epoch 70/100\n",
      "Learning rate:  0.0004\n",
      " - 59s - loss: 1.3263 - val_loss: 4.5441\n",
      "Epoch 71/100\n",
      "Learning rate:  0.0004\n",
      " - 59s - loss: 1.4556 - val_loss: 4.4692\n",
      "Epoch 72/100\n",
      "Learning rate:  0.0004\n",
      " - 59s - loss: 1.3768 - val_loss: 4.4116\n",
      "Epoch 73/100\n",
      "Learning rate:  0.0004\n",
      " - 59s - loss: 1.2277 - val_loss: 4.5164\n",
      "Epoch 74/100\n",
      "Learning rate:  0.0004\n",
      " - 59s - loss: 1.4437 - val_loss: 4.4771\n",
      "Epoch 75/100\n",
      "Learning rate:  0.0004\n",
      " - 59s - loss: 1.3955 - val_loss: 4.4422\n",
      "Epoch 76/100\n",
      "Learning rate:  0.0004\n",
      " - 59s - loss: 1.3013 - val_loss: 4.4051\n",
      "Epoch 77/100\n",
      "Learning rate:  0.0004\n",
      " - 59s - loss: 1.2031 - val_loss: 4.3883\n",
      "Epoch 78/100\n",
      "Learning rate:  0.0004\n",
      " - 59s - loss: 1.4628 - val_loss: 4.3847\n",
      "Epoch 79/100\n",
      "Learning rate:  0.0004\n",
      " - 59s - loss: 1.4451 - val_loss: 4.5339\n",
      "Epoch 80/100\n",
      "Learning rate:  0.0004\n",
      " - 59s - loss: 1.2608 - val_loss: 4.2944\n",
      "Epoch 81/100\n",
      "Learning rate:  0.0004\n",
      " - 59s - loss: 1.2354 - val_loss: 4.5255\n",
      "Epoch 82/100\n",
      "Learning rate:  0.0002\n",
      " - 59s - loss: 1.0877 - val_loss: 4.2514\n",
      "Epoch 83/100\n",
      "Learning rate:  0.0002\n",
      " - 59s - loss: 1.1145 - val_loss: 4.2907\n",
      "Epoch 84/100\n",
      "Learning rate:  0.0002\n",
      " - 59s - loss: 1.0708 - val_loss: 4.2100\n",
      "Epoch 85/100\n",
      "Learning rate:  0.0002\n",
      " - 59s - loss: 0.9697 - val_loss: 4.1809\n",
      "Epoch 86/100\n",
      "Learning rate:  0.0002\n",
      " - 59s - loss: 0.8942 - val_loss: 4.2143\n",
      "Epoch 87/100\n",
      "Learning rate:  0.0002\n",
      " - 59s - loss: 0.9183 - val_loss: 4.3537\n",
      "Epoch 88/100\n",
      "Learning rate:  0.0002\n",
      " - 59s - loss: 0.9277 - val_loss: 4.3687\n",
      "Epoch 89/100\n",
      "Learning rate:  0.0002\n",
      " - 59s - loss: 0.9425 - val_loss: 4.3614\n",
      "Epoch 90/100\n",
      "Learning rate:  0.0002\n",
      " - 59s - loss: 0.9425 - val_loss: 4.2824\n",
      "Epoch 91/100\n",
      "Learning rate:  0.0002\n",
      " - 59s - loss: 0.9853 - val_loss: 4.3008\n",
      "Epoch 92/100\n",
      "Learning rate:  0.0002\n",
      " - 58s - loss: 1.0298 - val_loss: 4.3915\n",
      "Epoch 93/100\n",
      "Learning rate:  0.0002\n",
      " - 59s - loss: 0.8075 - val_loss: 4.1404\n",
      "Epoch 94/100\n",
      "Learning rate:  0.0002\n",
      " - 59s - loss: 0.8726 - val_loss: 4.3206\n",
      "Epoch 95/100\n",
      "Learning rate:  0.0002\n",
      " - 59s - loss: 0.9068 - val_loss: 4.2180\n",
      "Epoch 96/100\n",
      "Learning rate:  0.0002\n",
      " - 59s - loss: 0.9232 - val_loss: 4.2103\n",
      "Epoch 97/100\n",
      "Learning rate:  0.0002\n",
      " - 59s - loss: 0.8071 - val_loss: 4.1861\n",
      "Epoch 98/100\n",
      "Learning rate:  0.0002\n",
      " - 60s - loss: 0.8796 - val_loss: 4.3847\n",
      "Epoch 99/100\n",
      "Learning rate:  0.0002\n",
      " - 59s - loss: 0.7731 - val_loss: 4.3069\n",
      "Epoch 100/100\n",
      "Learning rate:  0.0002\n",
      " - 58s - loss: 0.9498 - val_loss: 4.4482\n"
     ]
    }
   ],
   "source": [
    "# fit the mode\n",
    "history = triplet_model.fit_generator(train_generator, steps_per_epoch=74, epochs=100, \n",
    "                                      validation_data=val_generator, validation_steps=48, \n",
    "                                      verbose=2, callbacks=callbacks)\n",
    "\n",
    "base_model.save('./models/vgg16-base-0.5-model.h5')\n",
    "pickle.dump(history.history, open('./models/vgg16-triplet-0.5-history.p', 'wb'))\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training process\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.plot(train_loss, label='Training Loss')\n",
    "ax.plot(val_loss, label='Validation Loss')\n",
    "ax.set_title('Loss vs. Epochs', fontsize=16)\n",
    "ax.set_xlabel('Epochs', fontsize=14)\n",
    "ax.set_ylabel('Loss', fontsize=14)\n",
    "ax.legend(fontsize=14)\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features using Triplet Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t\t (113783, 4)\n",
      "Validation:\t (22255, 4)\n",
      "Test:\t\t (22391, 4)\n",
      "\n",
      "Train Landmarks:\t 14943\n",
      "Validation Landmarks:\t 7674\n",
      "Test Landmarks:\t\t 14436\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./data/triplet/train.csv')\n",
    "val_df = pd.read_csv('./data/triplet/validation.csv')\n",
    "test_df = pd.read_csv('./data/triplet/test.csv')\n",
    "\n",
    "print('Train:\\t\\t', train_df.shape)\n",
    "print('Validation:\\t', val_df.shape)\n",
    "print('Test:\\t\\t', test_df.shape)\n",
    "\n",
    "print('\\nTrain Landmarks:\\t', len(train_df['landmark_id'].unique()))\n",
    "print('Validation Landmarks:\\t', len(val_df['landmark_id'].unique()))\n",
    "print('Test Landmarks:\\t\\t', len(test_df['landmark_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "l2_norm (Lambda)             (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 7,079,424\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load trained model\n",
    "base_model = load_model('./models/vgg16-base-0.5-model.h5')\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train_imgs and test_imgs\n",
    "train_imgs = np.zeros(shape=(len(train_df), 512), dtype=np.float32)\n",
    "val_imgs = np.zeros(shape=(len(val_df), 512), dtype=np.float32)\n",
    "test_imgs = np.zeros(shape=(len(test_df), 512), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Process:          0\n",
      "================================================================================\n",
      "Process:      20000\n",
      "================================================================================\n",
      "Process:      40000\n",
      "================================================================================\n",
      "Process:      60000\n",
      "================================================================================\n",
      "Process:      80000\n",
      "================================================================================\n",
      "Process:     100000\n",
      "========================================================"
     ]
    }
   ],
   "source": [
    "# Process training images\n",
    "img_ids = train_df['image_id'].values\n",
    "steps = 20000\n",
    "for i in range(0, len(train_df), steps):\n",
    "    tmp_imgs = []\n",
    "    print('\\nProcess: {:10d}'.format(i))\n",
    "    \n",
    "    start = i\n",
    "    end = min(len(train_df), i + steps)\n",
    "    for idx in range(start, end):\n",
    "        if idx % 250 == 0:\n",
    "            print('=', end='')\n",
    "            \n",
    "        img_id = img_ids[idx]\n",
    "        path = './data/triplet/train/' + str(img_id) + '.jpg'\n",
    "        img = load_img(path, target_size=img_size[:2])\n",
    "        img = img_to_array(img)\n",
    "        tmp_imgs.append(img)\n",
    "        \n",
    "    tmp_imgs = np.array(tmp_imgs, dtype=np.float32) / 255.0\n",
    "    tmp_prediction = base_model.predict(tmp_imgs)\n",
    "    train_imgs[start: end, ] = tmp_prediction\n",
    "    _ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Process:          0\n",
      "================================================================================\n",
      "Process:       4000\n",
      "================================================================================\n",
      "Process:       8000\n",
      "================================================================================\n",
      "Process:      12000\n",
      "================================================================================\n",
      "Process:      16000\n",
      "================================================================================\n",
      "Process:      20000\n",
      "=============================================="
     ]
    }
   ],
   "source": [
    "# Process validation images\n",
    "img_ids = val_df['image_id'].values\n",
    "steps = 4000\n",
    "for i in range(0, len(val_df), steps):\n",
    "    tmp_imgs = []\n",
    "    print('\\nProcess: {:10d}'.format(i))\n",
    "    \n",
    "    start = i\n",
    "    end = min(len(val_df), i + steps)\n",
    "    for idx in range(start, end):\n",
    "        if idx % 50 == 0:\n",
    "            print('=', end='')\n",
    "            \n",
    "        img_id = img_ids[idx]\n",
    "        path = './data/triplet/validation/' + str(img_id) + '.jpg'\n",
    "        img = load_img(path, target_size=img_size[:2])\n",
    "        img = img_to_array(img)\n",
    "        tmp_imgs.append(img)\n",
    "        \n",
    "    tmp_imgs = np.array(tmp_imgs, dtype=np.float32) / 255.0\n",
    "    tmp_prediction = base_model.predict(tmp_imgs)\n",
    "    val_imgs[start: end, ] = tmp_prediction\n",
    "    _ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Process:          0\n",
      "================================================================================\n",
      "Process:       4000\n",
      "================================================================================\n",
      "Process:       8000\n",
      "================================================================================\n",
      "Process:      12000\n",
      "================================================================================\n",
      "Process:      16000\n",
      "================================================================================\n",
      "Process:      20000\n",
      "================================================"
     ]
    }
   ],
   "source": [
    "# Process test images\n",
    "img_ids = test_df['image_id'].values\n",
    "steps = 4000\n",
    "for i in range(0, len(test_df), steps):\n",
    "    tmp_imgs = []\n",
    "    print('\\nProcess: {:10d}'.format(i))\n",
    "    \n",
    "    start = i\n",
    "    end = min(len(test_df), i + steps)\n",
    "    for idx in range(start, end):\n",
    "        if idx % 50 == 0:\n",
    "            print('=', end='')\n",
    "            \n",
    "        img_id = img_ids[idx]\n",
    "        path = './data/triplet/test/' + str(img_id) + '.jpg'\n",
    "        img = load_img(path, target_size=img_size[:2])\n",
    "        img = img_to_array(img)\n",
    "        tmp_imgs.append(img)\n",
    "        \n",
    "    tmp_imgs = np.array(tmp_imgs, dtype=np.float32) / 255.0\n",
    "    tmp_prediction = base_model.predict(tmp_imgs)\n",
    "    test_imgs[start: end, ] = tmp_prediction\n",
    "    _ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t\t (113783, 512)\n",
      "Validation:\t (22255, 512)\n",
      "Test:\t\t (22391, 512)\n"
     ]
    }
   ],
   "source": [
    "print('Train:\\t\\t', train_imgs.shape)\n",
    "print('Validation:\\t', val_imgs.shape)\n",
    "print('Test:\\t\\t', test_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to disk\n",
    "np.save('./data/triplet/train-triplet-vgg16-0.5-features.npy', train_imgs)\n",
    "np.save('./data/triplet/validation-triplet-vgg16-0.5-features.npy', val_imgs)\n",
    "np.save('./data/triplet/test-triplet-vgg16-0.5-features.npy', test_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t\t (113783, 512) (113783, 4)\n",
      "Validation:\t (22255, 512) (22255, 4)\n",
      "Test:\t\t (22391, 512) (22391, 4)\n"
     ]
    }
   ],
   "source": [
    "# Already normalized\n",
    "train_feature = np.load('./data/triplet/train-triplet-vgg16-0.5-features.npy')\n",
    "val_feature = np.load('./data/triplet/validation-triplet-vgg16-0.5-features.npy')\n",
    "test_feature = np.load('./data/triplet/test-triplet-vgg16-0.5-features.npy')\n",
    "\n",
    "train_df = pd.read_csv('./data/triplet/train.csv')\n",
    "val_df = pd.read_csv('./data/triplet/validation.csv')\n",
    "test_df = pd.read_csv('./data/triplet/test.csv')\n",
    "\n",
    "print('Train:\\t\\t', train_feature.shape, train_df.shape)\n",
    "print('Validation:\\t', val_feature.shape, val_df.shape)\n",
    "print('Test:\\t\\t', test_feature.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def accuracy(true_label, prediction, top=1):\n",
    "    \"\"\" function to calculate the prediction accuracy \"\"\"\n",
    "    prediction = prediction[:, :top]\n",
    "    count = 0\n",
    "    for i in range(len(true_label)):\n",
    "        if true_label[i] in prediction[i]:\n",
    "            count += 1\n",
    "            \n",
    "    return count / len(true_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train and validation features\n",
    "train_val_feature = np.concatenate((train_feature, val_feature), axis=0)\n",
    "train_val_df = pd.concat((train_df, val_df), axis=0)\n",
    "train_val_df = train_val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=-1, n_neighbors=50, p=2, radius=1.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement KNN model\n",
    "knn = NearestNeighbors(n_neighbors=50, algorithm='auto', leaf_size=30, \n",
    "                       metric='minkowski', p=2, n_jobs=-1)\n",
    "knn.fit(train_val_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search the first 50 neighbors\n",
    "distance, neighbor_index = knn.kneighbors(test_feature, return_distance=True)\n",
    "\n",
    "# Save the results\n",
    "np.save('./result/knn-triplet-vgg16-0.5-distance.npy', distance)\n",
    "np.save('./result/knn-triplet-vgg16-0.5-neighbor.npy', neighbor_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_distance = np.load('./result/knn-triplet-vgg16-0.5-distance.npy')\n",
    "knn_neighbor = np.load('./result/knn-triplet-vgg16-0.5-neighbor.npy')\n",
    "\n",
    "# Get the first 50 neighbors\n",
    "predictions = []\n",
    "for neighbors in knn_neighbor:\n",
    "    predictions.append(train_val_df.loc[neighbors]['landmark_id'].values)\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "np.save('./result/knn-triplet-vgg16-0.5-test-prediction.npy', predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top  1 accuracy:\t 0.2881514894377205\n",
      "Top  5 accuracy:\t 0.46031887812067346\n",
      "Top 10 accuracy:\t 0.5360189361797151\n",
      "Top 20 accuracy:\t 0.6111830646241794\n"
     ]
    }
   ],
   "source": [
    "print('Top  1 accuracy:\\t', accuracy(test_df['landmark_id'].values, predictions, top=1))\n",
    "print('Top  5 accuracy:\\t', accuracy(test_df['landmark_id'].values, predictions, top=5))\n",
    "print('Top 10 accuracy:\\t', accuracy(test_df['landmark_id'].values, predictions, top=10))\n",
    "print('Top 20 accuracy:\\t', accuracy(test_df['landmark_id'].values, predictions, top=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_acc = []\n",
    "for i in range(1, 51):\n",
    "    tmp_acc = accuracy(test_df['landmark_id'].values, predictions, top=i)\n",
    "    knn_acc.append(tmp_acc)\n",
    "\n",
    "np.save('./result/knn-triplet-vgg16-0.5-accuracy.npy', knn_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
