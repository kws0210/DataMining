{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os, time, gc, random, pickle\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import requests, shutil\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Lambda\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t\t (113783, 4)\n",
      "Validation:\t (22255, 4)\n",
      "Test:\t\t (22391, 4)\n",
      "\n",
      "Train Landmarks:\t 14943\n",
      "Validation Landmarks:\t 7674\n",
      "Test Landmarks:\t\t 14436\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./data/triplet/train.csv')\n",
    "val_df = pd.read_csv('./data/triplet/validation.csv')\n",
    "test_df = pd.read_csv('./data/triplet/test.csv')\n",
    "\n",
    "print('Train:\\t\\t', train_df.shape)\n",
    "print('Validation:\\t', val_df.shape)\n",
    "print('Test:\\t\\t', test_df.shape)\n",
    "\n",
    "print('\\nTrain Landmarks:\\t', len(train_df['landmark_id'].unique()))\n",
    "print('Validation Landmarks:\\t', len(val_df['landmark_id'].unique()))\n",
    "print('Test Landmarks:\\t\\t', len(test_df['landmark_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>landmark_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>465272</td>\n",
       "      <td>a2ccf8ed2e969f6a</td>\n",
       "      <td>https://lh4.googleusercontent.com/-TPHkS5gzvm4...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64516</td>\n",
       "      <td>e205ca7c8dd7c027</td>\n",
       "      <td>https://lh3.googleusercontent.com/-V3RjsZtGpxE...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928409</td>\n",
       "      <td>4e8ab93c1620e8a3</td>\n",
       "      <td>http://mw2.google.com/mw-panoramio/photos/medi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88809</td>\n",
       "      <td>896bf928214d1ca4</td>\n",
       "      <td>http://lh5.ggpht.com/-Cy0l41uUaGA/R--yB8vy41I/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001133</td>\n",
       "      <td>375d2a153bdca926</td>\n",
       "      <td>http://lh6.ggpht.com/-UqzFpnqE9bU/S_0u1RovfdI/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                id  \\\n",
       "0    465272  a2ccf8ed2e969f6a   \n",
       "1     64516  e205ca7c8dd7c027   \n",
       "2    928409  4e8ab93c1620e8a3   \n",
       "3     88809  896bf928214d1ca4   \n",
       "4   1001133  375d2a153bdca926   \n",
       "\n",
       "                                                 url  landmark_id  \n",
       "0  https://lh4.googleusercontent.com/-TPHkS5gzvm4...            0  \n",
       "1  https://lh3.googleusercontent.com/-V3RjsZtGpxE...            0  \n",
       "2  http://mw2.google.com/mw-panoramio/photos/medi...            0  \n",
       "3  http://lh5.ggpht.com/-Cy0l41uUaGA/R--yB8vy41I/...            0  \n",
       "4  http://lh6.ggpht.com/-UqzFpnqE9bU/S_0u1RovfdI/...            0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set triplet generator\n",
    "def train_triplet_generator(df, batch_size=100, img_size=(224, 224), seed=42, \n",
    "                            prefix='./data/triplet/train/'):\n",
    "    \"\"\" training set triplet generator\n",
    "        it will generate 7400 triplet images in total\n",
    "    \"\"\"\n",
    "    # get images with only one training image landmark id and the rest landmark ids\n",
    "    np.random.seed(seed)\n",
    "    grouped = df[['landmark_id', 'image_id']].groupby('landmark_id').count().reset_index()\n",
    "    unique_neg_ids = list(grouped[grouped['image_id'] == 1]['landmark_id'].values)\n",
    "    rest_ids = list(grouped[grouped['image_id'] > 1]['landmark_id'].values)\n",
    "    size = 7400 * 2 - len(unique_neg_ids) \n",
    "    zeros = np.zeros((batch_size, 3, 1), dtype=K.floatx())\n",
    "    \n",
    "    while True:\n",
    "        # get positive and negative image landmark ids\n",
    "        np.random.shuffle(rest_ids)\n",
    "        candidate_ids = list(np.random.choice(rest_ids, size=size, replace=False))\n",
    "        pos_landmark_ids = candidate_ids[:7400]\n",
    "        neg_landmark_ids = candidate_ids[7400:] + unique_neg_ids\n",
    "        np.random.shuffle(neg_landmark_ids)\n",
    "        \n",
    "        # transform landmark id into image id\n",
    "        anc_img_ids = []\n",
    "        pos_img_ids = []\n",
    "        neg_img_ids = []\n",
    "        \n",
    "        for i in range(len(pos_landmark_ids)):\n",
    "            tmp_pos_ids = df[df['landmark_id'] == pos_landmark_ids[i]]['image_id'].values\n",
    "            anc_img_ids.append(tmp_pos_ids[0])\n",
    "            pos_img_ids.append(tmp_pos_ids[1])\n",
    "            \n",
    "            tmp_neg_ids = df[df['landmark_id'] == neg_landmark_ids[i]]['image_id'].values\n",
    "            neg_img_ids.append(tmp_neg_ids[0])\n",
    "        \n",
    "        # iterator to read batch images\n",
    "        for j in range(len(pos_img_ids) // batch_size):\n",
    "            batch_anc_img_ids = anc_img_ids[j * batch_size: (j + 1) * batch_size]\n",
    "            batch_pos_img_ids = pos_img_ids[j * batch_size: (j + 1) * batch_size]\n",
    "            batch_neg_img_ids = neg_img_ids[j * batch_size: (j + 1) * batch_size]\n",
    "            \n",
    "            # get images\n",
    "            anc_imgs = []\n",
    "            pos_imgs = []\n",
    "            neg_imgs = []\n",
    "            \n",
    "            # iteratively read images\n",
    "            for k in range(batch_size):\n",
    "                anc_path = prefix + str(batch_anc_img_ids[k]) + '.jpg'\n",
    "                pos_path = prefix + str(batch_pos_img_ids[k]) + '.jpg'\n",
    "                neg_path = prefix + str(batch_neg_img_ids[k]) + '.jpg'\n",
    "                \n",
    "                tmp_anc_img = load_img(anc_path, target_size=img_size)\n",
    "                tmp_anc_img = img_to_array(tmp_anc_img)\n",
    "                anc_imgs.append(tmp_anc_img)\n",
    "                \n",
    "                tmp_pos_img = load_img(pos_path, target_size=img_size)\n",
    "                tmp_pos_img = img_to_array(tmp_pos_img)\n",
    "                pos_imgs.append(tmp_pos_img)\n",
    "                \n",
    "                tmp_neg_img = load_img(neg_path, target_size=img_size)\n",
    "                tmp_neg_img = img_to_array(tmp_neg_img)\n",
    "                neg_imgs.append(tmp_neg_img)\n",
    "        \n",
    "            # transform list to array\n",
    "            anc_imgs = np.array(anc_imgs, dtype=K.floatx()) / 255.0\n",
    "            pos_imgs = np.array(pos_imgs, dtype=K.floatx()) / 255.0\n",
    "            neg_imgs = np.array(neg_imgs, dtype=K.floatx()) / 255.0\n",
    "\n",
    "            yield [anc_imgs, pos_imgs, neg_imgs], zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation set triplet generator\n",
    "def val_triplet_generator(df, batch_size=128, img_size=(224, 224), \n",
    "                          seed=42, prefix='./data/triplet/validation'):\n",
    "    \"\"\" validation set triplet collector \"\"\"\n",
    "    \n",
    "     # get images with only one image landmark id and the rest landmark ids\n",
    "    grouped = df[['landmark_id', 'image_id']].groupby('landmark_id').count().reset_index()\n",
    "    unique_neg_ids = list(grouped[grouped['image_id'] == 1]['landmark_id'].values)\n",
    "    rest_ids = list(grouped[grouped['image_id'] > 1]['landmark_id'].values)\n",
    "    size = 3072 * 2 - len(unique_neg_ids) \n",
    "    zeros = np.zeros((batch_size, 3, 1), dtype=K.floatx())\n",
    "    \n",
    "    while True:\n",
    "        # get positive and negative image landmark ids\n",
    "        np.random.seed(seed)\n",
    "        candidate_ids = list(np.random.choice(rest_ids, size=size, replace=False))\n",
    "        pos_landmark_ids = candidate_ids[:3072]\n",
    "        neg_landmark_ids = candidate_ids[3072:] + unique_neg_ids\n",
    "        np.random.shuffle(neg_landmark_ids)\n",
    "        \n",
    "        # transform landmark id into image id\n",
    "        anc_img_ids = []\n",
    "        pos_img_ids = []\n",
    "        neg_img_ids = []\n",
    "        \n",
    "        for i in range(len(pos_landmark_ids)):\n",
    "            tmp_pos_ids = df[df['landmark_id'] == pos_landmark_ids[i]]['image_id'].values\n",
    "            anc_img_ids.append(tmp_pos_ids[0])\n",
    "            pos_img_ids.append(tmp_pos_ids[1])\n",
    "            \n",
    "            tmp_neg_ids = df[df['landmark_id'] == neg_landmark_ids[i]]['image_id'].values\n",
    "            neg_img_ids.append(tmp_neg_ids[0])\n",
    "        \n",
    "        # iterator to read batch images\n",
    "        for j in range(len(pos_img_ids) // batch_size):\n",
    "            batch_anc_img_ids = anc_img_ids[j * batch_size: (j + 1) * batch_size]\n",
    "            batch_pos_img_ids = pos_img_ids[j * batch_size: (j + 1) * batch_size]\n",
    "            batch_neg_img_ids = neg_img_ids[j * batch_size: (j + 1) * batch_size]\n",
    "            \n",
    "            # get images\n",
    "            anc_imgs = []\n",
    "            pos_imgs = []\n",
    "            neg_imgs = []\n",
    "            \n",
    "            # iteratively read images\n",
    "            for k in range(batch_size):\n",
    "                anc_path = prefix + str(batch_anc_img_ids[k]) + '.jpg'\n",
    "                pos_path = prefix + str(batch_pos_img_ids[k]) + '.jpg'\n",
    "                neg_path = prefix + str(batch_neg_img_ids[k]) + '.jpg'\n",
    "                \n",
    "                tmp_anc_img = load_img(anc_path, target_size=img_size)\n",
    "                tmp_anc_img = img_to_array(tmp_anc_img)\n",
    "                anc_imgs.append(tmp_anc_img)\n",
    "                \n",
    "                tmp_pos_img = load_img(pos_path, target_size=img_size)\n",
    "                tmp_pos_img = img_to_array(tmp_pos_img)\n",
    "                pos_imgs.append(tmp_pos_img)\n",
    "                \n",
    "                tmp_neg_img = load_img(neg_path, target_size=img_size)\n",
    "                tmp_neg_img = img_to_array(tmp_neg_img)\n",
    "                neg_imgs.append(tmp_neg_img)\n",
    "        \n",
    "            # transform list to array\n",
    "            anc_imgs = np.array(anc_imgs, dtype=K.floatx()) / 255.0\n",
    "            pos_imgs = np.array(pos_imgs, dtype=K.floatx()) / 255.0\n",
    "            neg_imgs = np.array(neg_imgs, dtype=K.floatx()) / 255.0\n",
    "            \n",
    "            yield [anc_imgs, pos_imgs, neg_imgs], zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Triplet Loss Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base network for triplet network\n",
    "def base_net(input_shape=(224, 224, 3)):\n",
    "    \"\"\" define triplet network \"\"\"\n",
    "    # load pre-trained InceptionV3 model\n",
    "    inception = InceptionV3(include_top=False, weights='imagenet', input_shape=input_shape, pooling='avg')\n",
    "    \n",
    "    # frozen shallow layers\n",
    "    inception.trainable = True\n",
    "    \n",
    "    set_trainable = False\n",
    "    for layer in inception.layers:\n",
    "        if layer.name == 'mixed9':\n",
    "            set_trainable = True\n",
    "            \n",
    "        if set_trainable:\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "    \n",
    "    # define sequential model\n",
    "    model = Sequential(name='base_net')\n",
    "    model.add(inception)\n",
    "    model.add(Lambda(lambda x: K.l2_normalize(x, axis=1), name='l2_norm'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define triplet network\n",
    "def triplet_net(base_model, input_shape=(224, 224, 3)):\n",
    "    \"\"\" function to define triplet networks \"\"\"\n",
    "    # define input: anchor, positive, negative\n",
    "    anchor = Input(shape=input_shape, name='anchor_input')\n",
    "    positive = Input(shape=input_shape, name='positive_input')\n",
    "    negative = Input(shape=input_shape, name='negative_input')\n",
    "    \n",
    "    # extract vector represent using CNN based model\n",
    "    anc_vec = base_model(anchor)\n",
    "    pos_vec = base_model(positive)\n",
    "    neg_vec = base_model(negative)\n",
    "    \n",
    "    # stack outputs\n",
    "    stacks = Lambda(lambda x: K.stack(x, axis=1), name='output')([anc_vec, pos_vec, neg_vec])\n",
    "\n",
    "    # define inputs and outputs\n",
    "    inputs=[anchor, positive, negative]\n",
    "    outputs = stacks\n",
    "    \n",
    "    # define the triplet model\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='triplet_net')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define triplet loss\n",
    "def triplet_loss(y_true, y_pred):\n",
    "    \"\"\" function to compute triplet loss\n",
    "        margin is predefined coded, manually change if needed\n",
    "    \"\"\"\n",
    "    # define triplet margin\n",
    "    margin = K.constant(0.5)\n",
    "    zero = K.constant(0.0)\n",
    "    \n",
    "    # get the prediction vector\n",
    "    anchor, positive, negative = y_pred[:, 0], y_pred[:, 1], y_pred[:, 2]\n",
    "    \n",
    "    # compute distance\n",
    "    pos_distance = K.sum(K.square(anchor - positive), axis=1)\n",
    "    neg_distance = K.sum(K.square(anchor - negative), axis=1)\n",
    "    \n",
    "    # compute loss\n",
    "    partial_loss = pos_distance - neg_distance + margin\n",
    "    full_loss = K.sum(K.maximum(partial_loss, zero), axis=0)\n",
    "    \n",
    "    return full_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Triplet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproduciable purpose\n",
    "seed = 42\n",
    "K.clear_session()\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "tf.set_random_seed(seed)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "# Define Parameters\n",
    "img_size = (224, 224, 3)  # target image size\n",
    "\n",
    "# triplet image generator\n",
    "train_generator = train_triplet_generator(train_df, batch_size=100, img_size=img_size[:2], \n",
    "                                          seed=42, prefix='./data/triplet/train/')\n",
    "\n",
    "val_generator = val_triplet_generator(val_df, batch_size=64, img_size=img_size[:2], \n",
    "                                      seed=42, prefix='./data/triplet/validation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3148: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 2048)              21802784  \n",
      "_________________________________________________________________\n",
      "l2_norm (Lambda)             (None, 2048)              0         \n",
      "=================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 6,073,536\n",
      "Non-trainable params: 15,729,248\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define triplet network model\n",
    "base_model = base_net(input_shape=img_size)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "base_net (Sequential)           (None, 2048)         21802784    anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "output (Lambda)                 (None, 3, 2048)      0           base_net[1][0]                   \n",
      "                                                                 base_net[2][0]                   \n",
      "                                                                 base_net[3][0]                   \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 6,073,536\n",
      "Non-trainable params: 15,729,248\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "triplet_model = triplet_net(base_model=base_model, input_shape=img_size)\n",
    "triplet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Triplet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n"
     ]
    }
   ],
   "source": [
    "# define learning scheduler\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\" Learning rate schedule \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 80:\n",
    "        lr *= 2e-1\n",
    "    elif epoch > 60:\n",
    "        lr *= 4e-1\n",
    "    elif epoch > 40:\n",
    "        lr *= 6e-1\n",
    "    elif epoch > 20:\n",
    "        lr *= 8e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "# define optimizer\n",
    "opt = keras.optimizers.Adam(lr=lr_schedule(0))\n",
    "\n",
    "# Create call backs\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "callbacks = [lr_reducer, lr_scheduler]\n",
    "\n",
    "# compile the model\n",
    "triplet_model.compile(optimizer=opt, loss=triplet_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Learning rate:  0.001\n",
      " - 74s - loss: 13.1073 - val_loss: 7.0983\n",
      "Epoch 2/100\n",
      "Learning rate:  0.001\n",
      " - 51s - loss: 7.4170 - val_loss: 6.6718\n",
      "Epoch 3/100\n",
      "Learning rate:  0.001\n",
      " - 51s - loss: 5.8414 - val_loss: 6.6345\n",
      "Epoch 4/100\n",
      "Learning rate:  0.001\n",
      " - 52s - loss: 5.6698 - val_loss: 6.6671\n",
      "Epoch 5/100\n",
      "Learning rate:  0.001\n",
      " - 51s - loss: 4.8367 - val_loss: 6.8114\n",
      "Epoch 6/100\n",
      "Learning rate:  0.001\n",
      " - 51s - loss: 4.0112 - val_loss: 6.5010\n",
      "Epoch 7/100\n",
      "Learning rate:  0.001\n",
      " - 52s - loss: 3.7425 - val_loss: 6.2423\n",
      "Epoch 8/100\n",
      "Learning rate:  0.001\n",
      " - 52s - loss: 3.4530 - val_loss: 6.6010\n",
      "Epoch 9/100\n",
      "Learning rate:  0.001\n",
      " - 51s - loss: 3.3124 - val_loss: 6.1234\n",
      "Epoch 10/100\n",
      "Learning rate:  0.001\n",
      " - 51s - loss: 2.9464 - val_loss: 5.8880\n",
      "Epoch 11/100\n",
      "Learning rate:  0.001\n",
      " - 52s - loss: 2.8867 - val_loss: 5.9803\n",
      "Epoch 12/100\n",
      "Learning rate:  0.001\n",
      " - 52s - loss: 2.5973 - val_loss: 6.0964\n",
      "Epoch 13/100\n",
      "Learning rate:  0.001\n",
      " - 51s - loss: 2.4248 - val_loss: 5.9724\n",
      "Epoch 14/100\n",
      "Learning rate:  0.001\n",
      " - 52s - loss: 1.9734 - val_loss: 5.9823\n",
      "Epoch 15/100\n",
      "Learning rate:  0.001\n",
      " - 52s - loss: 1.9831 - val_loss: 5.9676\n",
      "Epoch 16/100\n",
      "Learning rate:  0.001\n",
      " - 54s - loss: 2.0514 - val_loss: 5.6638\n",
      "Epoch 17/100\n",
      "Learning rate:  0.001\n",
      " - 51s - loss: 1.8209 - val_loss: 5.6328\n",
      "Epoch 18/100\n",
      "Learning rate:  0.001\n",
      " - 51s - loss: 1.8862 - val_loss: 5.6949\n",
      "Epoch 19/100\n",
      "Learning rate:  0.001\n",
      " - 51s - loss: 1.7823 - val_loss: 6.0302\n",
      "Epoch 20/100\n",
      "Learning rate:  0.001\n",
      " - 52s - loss: 1.7000 - val_loss: 6.0305\n",
      "Epoch 21/100\n",
      "Learning rate:  0.001\n",
      " - 53s - loss: 1.5422 - val_loss: 6.1026\n",
      "Epoch 22/100\n",
      "Learning rate:  0.0008\n",
      " - 52s - loss: 1.4682 - val_loss: 5.9289\n",
      "Epoch 23/100\n",
      "Learning rate:  0.0008\n",
      " - 52s - loss: 1.5050 - val_loss: 5.8299\n",
      "Epoch 24/100\n",
      "Learning rate:  0.0008\n",
      " - 51s - loss: 1.5015 - val_loss: 6.3501\n",
      "Epoch 25/100\n",
      "Learning rate:  0.0008\n",
      " - 53s - loss: 1.3716 - val_loss: 5.9381\n",
      "Epoch 26/100\n",
      "Learning rate:  0.0008\n",
      " - 53s - loss: 1.2726 - val_loss: 5.9097\n",
      "Epoch 27/100\n",
      "Learning rate:  0.0008\n",
      " - 51s - loss: 1.2923 - val_loss: 5.8216\n",
      "Epoch 28/100\n",
      "Learning rate:  0.0008\n",
      " - 52s - loss: 1.1755 - val_loss: 6.1377\n",
      "Epoch 29/100\n",
      "Learning rate:  0.0008\n",
      " - 52s - loss: 1.1220 - val_loss: 5.8967\n",
      "Epoch 30/100\n",
      "Learning rate:  0.0008\n",
      " - 53s - loss: 1.1050 - val_loss: 6.0679\n",
      "Epoch 31/100\n",
      "Learning rate:  0.0008\n",
      " - 52s - loss: 1.1484 - val_loss: 6.0172\n",
      "Epoch 32/100\n",
      "Learning rate:  0.0008\n",
      " - 52s - loss: 1.1318 - val_loss: 6.2355\n",
      "Epoch 33/100\n",
      "Learning rate:  0.0008\n",
      " - 54s - loss: 1.2129 - val_loss: 6.2798\n",
      "Epoch 34/100\n",
      "Learning rate:  0.0008\n",
      " - 50s - loss: 1.0507 - val_loss: 6.0746\n",
      "Epoch 35/100\n",
      "Learning rate:  0.0008\n",
      " - 54s - loss: 1.1537 - val_loss: 5.8999\n",
      "Epoch 36/100\n",
      "Learning rate:  0.0008\n",
      " - 52s - loss: 0.9075 - val_loss: 6.2001\n",
      "Epoch 37/100\n",
      "Learning rate:  0.0008\n",
      " - 56s - loss: 1.0405 - val_loss: 6.0776\n",
      "Epoch 38/100\n",
      "Learning rate:  0.0008\n",
      " - 52s - loss: 0.9238 - val_loss: 6.1029\n",
      "Epoch 39/100\n",
      "Learning rate:  0.0008\n",
      " - 50s - loss: 1.0756 - val_loss: 6.2901\n",
      "Epoch 40/100\n",
      "Learning rate:  0.0008\n",
      " - 50s - loss: 0.9040 - val_loss: 5.9292\n",
      "Epoch 41/100\n",
      "Learning rate:  0.0008\n",
      " - 53s - loss: 0.9733 - val_loss: 6.0396\n",
      "Epoch 42/100\n",
      "Learning rate:  0.0006\n",
      " - 52s - loss: 0.9316 - val_loss: 6.0094\n",
      "Epoch 43/100\n",
      "Learning rate:  0.0006\n",
      " - 51s - loss: 0.8981 - val_loss: 6.0230\n",
      "Epoch 44/100\n",
      "Learning rate:  0.0006\n",
      " - 53s - loss: 0.8383 - val_loss: 6.0613\n",
      "Epoch 45/100\n",
      "Learning rate:  0.0006\n",
      " - 51s - loss: 0.7737 - val_loss: 5.9739\n",
      "Epoch 46/100\n",
      "Learning rate:  0.0006\n",
      " - 51s - loss: 0.8629 - val_loss: 6.0113\n",
      "Epoch 47/100\n",
      "Learning rate:  0.0006\n",
      " - 51s - loss: 0.7292 - val_loss: 5.8411\n",
      "Epoch 48/100\n",
      "Learning rate:  0.0006\n",
      " - 53s - loss: 0.7768 - val_loss: 5.9467\n",
      "Epoch 49/100\n",
      "Learning rate:  0.0006\n",
      " - 50s - loss: 0.7682 - val_loss: 5.9711\n",
      "Epoch 50/100\n",
      "Learning rate:  0.0006\n",
      " - 51s - loss: 0.7096 - val_loss: 6.1058\n",
      "Epoch 51/100\n",
      "Learning rate:  0.0006\n",
      " - 51s - loss: 0.6372 - val_loss: 6.0332\n",
      "Epoch 52/100\n",
      "Learning rate:  0.0006\n",
      " - 52s - loss: 0.6624 - val_loss: 5.9515\n",
      "Epoch 53/100\n",
      "Learning rate:  0.0006\n",
      " - 52s - loss: 0.6704 - val_loss: 6.1254\n",
      "Epoch 54/100\n",
      "Learning rate:  0.0006\n",
      " - 51s - loss: 0.6441 - val_loss: 6.2062\n",
      "Epoch 55/100\n",
      "Learning rate:  0.0006\n",
      " - 51s - loss: 0.7316 - val_loss: 6.0161\n",
      "Epoch 56/100\n",
      "Learning rate:  0.0006\n",
      " - 50s - loss: 0.6615 - val_loss: 6.1041\n",
      "Epoch 57/100\n",
      "Learning rate:  0.0006\n",
      " - 51s - loss: 0.6552 - val_loss: 6.2155\n",
      "Epoch 58/100\n",
      "Learning rate:  0.0006\n",
      " - 51s - loss: 0.6357 - val_loss: 6.0481\n",
      "Epoch 59/100\n",
      "Learning rate:  0.0006\n",
      " - 51s - loss: 0.6036 - val_loss: 6.0829\n",
      "Epoch 60/100\n",
      "Learning rate:  0.0006\n",
      " - 51s - loss: 0.5661 - val_loss: 5.9583\n",
      "Epoch 61/100\n",
      "Learning rate:  0.0006\n",
      " - 51s - loss: 0.6512 - val_loss: 5.9537\n",
      "Epoch 62/100\n",
      "Learning rate:  0.0004\n",
      " - 51s - loss: 0.5571 - val_loss: 5.7778\n",
      "Epoch 63/100\n",
      "Learning rate:  0.0004\n",
      " - 50s - loss: 0.6152 - val_loss: 5.6848\n",
      "Epoch 64/100\n",
      "Learning rate:  0.0004\n",
      " - 52s - loss: 0.5405 - val_loss: 5.8194\n",
      "Epoch 65/100\n",
      "Learning rate:  0.0004\n",
      " - 51s - loss: 0.5669 - val_loss: 5.8790\n",
      "Epoch 66/100\n",
      "Learning rate:  0.0004\n",
      " - 52s - loss: 0.5546 - val_loss: 5.9236\n",
      "Epoch 67/100\n",
      "Learning rate:  0.0004\n",
      " - 52s - loss: 0.5584 - val_loss: 5.8222\n",
      "Epoch 68/100\n",
      "Learning rate:  0.0004\n",
      " - 54s - loss: 0.5711 - val_loss: 5.9093\n",
      "Epoch 69/100\n",
      "Learning rate:  0.0004\n",
      " - 51s - loss: 0.5183 - val_loss: 6.1349\n",
      "Epoch 70/100\n",
      "Learning rate:  0.0004\n",
      " - 55s - loss: 0.4371 - val_loss: 6.0797\n",
      "Epoch 71/100\n",
      "Learning rate:  0.0004\n",
      " - 52s - loss: 0.5116 - val_loss: 6.1132\n",
      "Epoch 72/100\n",
      "Learning rate:  0.0004\n",
      " - 51s - loss: 0.4257 - val_loss: 5.8953\n",
      "Epoch 73/100\n",
      "Learning rate:  0.0004\n",
      " - 52s - loss: 0.4427 - val_loss: 5.9251\n",
      "Epoch 74/100\n",
      "Learning rate:  0.0004\n",
      " - 51s - loss: 0.4020 - val_loss: 5.7654\n",
      "Epoch 75/100\n",
      "Learning rate:  0.0004\n",
      " - 52s - loss: 0.4757 - val_loss: 5.7048\n",
      "Epoch 76/100\n",
      "Learning rate:  0.0004\n",
      " - 51s - loss: 0.4245 - val_loss: 5.8184\n",
      "Epoch 77/100\n",
      "Learning rate:  0.0004\n",
      " - 52s - loss: 0.4754 - val_loss: 5.7333\n",
      "Epoch 78/100\n",
      "Learning rate:  0.0004\n",
      " - 51s - loss: 0.5014 - val_loss: 5.8628\n",
      "Epoch 79/100\n",
      "Learning rate:  0.0004\n",
      " - 51s - loss: 0.4835 - val_loss: 5.9025\n",
      "Epoch 80/100\n",
      "Learning rate:  0.0004\n",
      " - 50s - loss: 0.4824 - val_loss: 6.0185\n",
      "Epoch 81/100\n",
      "Learning rate:  0.0004\n",
      " - 54s - loss: 0.4404 - val_loss: 6.0544\n",
      "Epoch 82/100\n",
      "Learning rate:  0.0002\n",
      " - 50s - loss: 0.3997 - val_loss: 6.1747\n",
      "Epoch 83/100\n",
      "Learning rate:  0.0002\n",
      " - 53s - loss: 0.4188 - val_loss: 6.3227\n",
      "Epoch 84/100\n",
      "Learning rate:  0.0002\n",
      " - 51s - loss: 0.4371 - val_loss: 6.1283\n",
      "Epoch 85/100\n",
      "Learning rate:  0.0002\n",
      " - 51s - loss: 0.3691 - val_loss: 6.0628\n",
      "Epoch 86/100\n",
      "Learning rate:  0.0002\n",
      " - 51s - loss: 0.3794 - val_loss: 6.0261\n",
      "Epoch 87/100\n",
      "Learning rate:  0.0002\n",
      " - 51s - loss: 0.3191 - val_loss: 5.9746\n",
      "Epoch 88/100\n",
      "Learning rate:  0.0002\n",
      " - 51s - loss: 0.3439 - val_loss: 5.9212\n",
      "Epoch 89/100\n",
      "Learning rate:  0.0002\n",
      " - 52s - loss: 0.3541 - val_loss: 5.8431\n",
      "Epoch 90/100\n",
      "Learning rate:  0.0002\n",
      " - 51s - loss: 0.3180 - val_loss: 5.8122\n",
      "Epoch 91/100\n",
      "Learning rate:  0.0002\n",
      " - 51s - loss: 0.3426 - val_loss: 5.8366\n",
      "Epoch 92/100\n",
      "Learning rate:  0.0002\n",
      " - 51s - loss: 0.3115 - val_loss: 5.8174\n",
      "Epoch 93/100\n",
      "Learning rate:  0.0002\n",
      " - 52s - loss: 0.3072 - val_loss: 5.8005\n",
      "Epoch 94/100\n",
      "Learning rate:  0.0002\n",
      " - 54s - loss: 0.3167 - val_loss: 5.8049\n",
      "Epoch 95/100\n",
      "Learning rate:  0.0002\n",
      " - 51s - loss: 0.2913 - val_loss: 5.7831\n",
      "Epoch 96/100\n",
      "Learning rate:  0.0002\n",
      " - 51s - loss: 0.3198 - val_loss: 5.8318\n",
      "Epoch 97/100\n",
      "Learning rate:  0.0002\n",
      " - 54s - loss: 0.3104 - val_loss: 5.7921\n",
      "Epoch 98/100\n",
      "Learning rate:  0.0002\n",
      " - 56s - loss: 0.3145 - val_loss: 5.8124\n",
      "Epoch 99/100\n",
      "Learning rate:  0.0002\n",
      " - 53s - loss: 0.2700 - val_loss: 5.8203\n",
      "Epoch 100/100\n",
      "Learning rate:  0.0002\n",
      " - 51s - loss: 0.3488 - val_loss: 5.7805\n"
     ]
    }
   ],
   "source": [
    "# fit the mode\n",
    "history = triplet_model.fit_generator(train_generator, steps_per_epoch=74, epochs=100, \n",
    "                                      validation_data=val_generator, validation_steps=48, \n",
    "                                      verbose=2, callbacks=callbacks)\n",
    "\n",
    "base_model.save('./models/inception-base-0.5-model.h5')\n",
    "pickle.dump(history.history, open('./models/inception-triplet-0.5-history.p', 'wb'))\n",
    "_ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training process\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.plot(train_loss, label='Training Loss')\n",
    "ax.plot(val_loss, label='Validation Loss')\n",
    "ax.set_title('Loss vs. Epochs', fontsize=16)\n",
    "ax.set_xlabel('Epochs', fontsize=14)\n",
    "ax.set_ylabel('Loss', fontsize=14)\n",
    "ax.legend(fontsize=14)\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features using Triplet Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t\t (113783, 4)\n",
      "Validation:\t (22255, 4)\n",
      "Test:\t\t (22391, 4)\n",
      "\n",
      "Train Landmarks:\t 14943\n",
      "Validation Landmarks:\t 7674\n",
      "Test Landmarks:\t\t 14436\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./data/triplet/train.csv')\n",
    "val_df = pd.read_csv('./data/triplet/validation.csv')\n",
    "test_df = pd.read_csv('./data/triplet/test.csv')\n",
    "\n",
    "print('Train:\\t\\t', train_df.shape)\n",
    "print('Validation:\\t', val_df.shape)\n",
    "print('Test:\\t\\t', test_df.shape)\n",
    "\n",
    "print('\\nTrain Landmarks:\\t', len(train_df['landmark_id'].unique()))\n",
    "print('Validation Landmarks:\\t', len(val_df['landmark_id'].unique()))\n",
    "print('Test Landmarks:\\t\\t', len(test_df['landmark_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_v3 (Model)         (None, 2048)              21802784  \n",
      "_________________________________________________________________\n",
      "l2_norm (Lambda)             (None, 2048)              0         \n",
      "=================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 6,073,536\n",
      "Non-trainable params: 15,729,248\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load trained model\n",
    "base_model = load_model('./models/inception-base-0.5-model.h5')\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train_imgs and test_imgs\n",
    "train_imgs = np.zeros(shape=(len(train_df), 2048), dtype=np.float32)\n",
    "val_imgs = np.zeros(shape=(len(val_df), 2048), dtype=np.float32)\n",
    "test_imgs = np.zeros(shape=(len(test_df), 2048), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Process:          0\n",
      "================================================================================\n",
      "Process:      20000\n",
      "================================================================================\n",
      "Process:      40000\n",
      "================================================================================\n",
      "Process:      60000\n",
      "================================================================================\n",
      "Process:      80000\n",
      "================================================================================\n",
      "Process:     100000\n",
      "========================================================"
     ]
    }
   ],
   "source": [
    "# Process training images\n",
    "img_ids = train_df['image_id'].values\n",
    "steps = 20000\n",
    "for i in range(0, len(train_df), steps):\n",
    "    tmp_imgs = []\n",
    "    print('\\nProcess: {:10d}'.format(i))\n",
    "    \n",
    "    start = i\n",
    "    end = min(len(train_df), i + steps)\n",
    "    for idx in range(start, end):\n",
    "        if idx % 250 == 0:\n",
    "            print('=', end='')\n",
    "            \n",
    "        img_id = img_ids[idx]\n",
    "        path = './data/triplet/train/' + str(img_id) + '.jpg'\n",
    "        img = load_img(path, target_size=img_size[:2])\n",
    "        img = img_to_array(img)\n",
    "        tmp_imgs.append(img)\n",
    "        \n",
    "    tmp_imgs = np.array(tmp_imgs, dtype=np.float32) / 255.0\n",
    "    tmp_prediction = base_model.predict(tmp_imgs)\n",
    "    train_imgs[start: end, ] = tmp_prediction\n",
    "    _ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Process:          0\n",
      "================================================================================\n",
      "Process:       4000\n",
      "================================================================================\n",
      "Process:       8000\n",
      "================================================================================\n",
      "Process:      12000\n",
      "================================================================================\n",
      "Process:      16000\n",
      "================================================================================\n",
      "Process:      20000\n",
      "=============================================="
     ]
    }
   ],
   "source": [
    "# Process validation images\n",
    "img_ids = val_df['image_id'].values\n",
    "steps = 4000\n",
    "for i in range(0, len(val_df), steps):\n",
    "    tmp_imgs = []\n",
    "    print('\\nProcess: {:10d}'.format(i))\n",
    "    \n",
    "    start = i\n",
    "    end = min(len(val_df), i + steps)\n",
    "    for idx in range(start, end):\n",
    "        if idx % 50 == 0:\n",
    "            print('=', end='')\n",
    "            \n",
    "        img_id = img_ids[idx]\n",
    "        path = './data/triplet/validation/' + str(img_id) + '.jpg'\n",
    "        img = load_img(path, target_size=img_size[:2])\n",
    "        img = img_to_array(img)\n",
    "        tmp_imgs.append(img)\n",
    "        \n",
    "    tmp_imgs = np.array(tmp_imgs, dtype=np.float32) / 255.0\n",
    "    tmp_prediction = base_model.predict(tmp_imgs)\n",
    "    val_imgs[start: end, ] = tmp_prediction\n",
    "    _ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Process:          0\n",
      "================================================================================\n",
      "Process:       4000\n",
      "================================================================================\n",
      "Process:       8000\n",
      "================================================================================\n",
      "Process:      12000\n",
      "================================================================================\n",
      "Process:      16000\n",
      "================================================================================\n",
      "Process:      20000\n",
      "================================================"
     ]
    }
   ],
   "source": [
    "# Process test images\n",
    "img_ids = test_df['image_id'].values\n",
    "steps = 4000\n",
    "for i in range(0, len(test_df), steps):\n",
    "    tmp_imgs = []\n",
    "    print('\\nProcess: {:10d}'.format(i))\n",
    "    \n",
    "    start = i\n",
    "    end = min(len(test_df), i + steps)\n",
    "    for idx in range(start, end):\n",
    "        if idx % 50 == 0:\n",
    "            print('=', end='')\n",
    "            \n",
    "        img_id = img_ids[idx]\n",
    "        path = './data/triplet/test/' + str(img_id) + '.jpg'\n",
    "        img = load_img(path, target_size=img_size[:2])\n",
    "        img = img_to_array(img)\n",
    "        tmp_imgs.append(img)\n",
    "        \n",
    "    tmp_imgs = np.array(tmp_imgs, dtype=np.float32) / 255.0\n",
    "    tmp_prediction = base_model.predict(tmp_imgs)\n",
    "    test_imgs[start: end, ] = tmp_prediction\n",
    "    _ = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t\t (113783, 2048)\n",
      "Validation:\t (22255, 2048)\n",
      "Test:\t\t (22391, 2048)\n"
     ]
    }
   ],
   "source": [
    "print('Train:\\t\\t', train_imgs.shape)\n",
    "print('Validation:\\t', val_imgs.shape)\n",
    "print('Test:\\t\\t', test_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to disk\n",
    "np.save('./data/triplet/train-triplet-inception-0.5-features.npy', train_imgs)\n",
    "np.save('./data/triplet/validation-triplet-inception-0.5-features.npy', val_imgs)\n",
    "np.save('./data/triplet/test-triplet-inception-0.5-features.npy', test_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\t\t (113783, 2048) (113783, 4)\n",
      "Validation:\t (22255, 2048) (22255, 4)\n",
      "Test:\t\t (22391, 2048) (22391, 4)\n"
     ]
    }
   ],
   "source": [
    "# Already normalized\n",
    "train_feature = np.load('./data/triplet/train-triplet-inception-0.5-features.npy')\n",
    "val_feature = np.load('./data/triplet/validation-triplet-inception-0.5-features.npy')\n",
    "test_feature = np.load('./data/triplet/test-triplet-inception-0.5-features.npy')\n",
    "\n",
    "train_df = pd.read_csv('./data/triplet/train.csv')\n",
    "val_df = pd.read_csv('./data/triplet/validation.csv')\n",
    "test_df = pd.read_csv('./data/triplet/test.csv')\n",
    "\n",
    "print('Train:\\t\\t', train_feature.shape, train_df.shape)\n",
    "print('Validation:\\t', val_feature.shape, val_df.shape)\n",
    "print('Test:\\t\\t', test_feature.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def accuracy(true_label, prediction, top=1):\n",
    "    \"\"\" function to calculate the prediction accuracy \"\"\"\n",
    "    prediction = prediction[:, :top]\n",
    "    count = 0\n",
    "    for i in range(len(true_label)):\n",
    "        if true_label[i] in prediction[i]:\n",
    "            count += 1\n",
    "            \n",
    "    return count / len(true_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train and validation features\n",
    "train_val_feature = np.concatenate((train_feature, val_feature), axis=0)\n",
    "train_val_df = pd.concat((train_df, val_df), axis=0)\n",
    "train_val_df = train_val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=-1, n_neighbors=50, p=2, radius=1.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement KNN model\n",
    "knn = NearestNeighbors(n_neighbors=50, algorithm='auto', leaf_size=30, \n",
    "                       metric='minkowski', p=2, n_jobs=-1)\n",
    "knn.fit(train_val_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search the first 50 neighbors\n",
    "distance, neighbor_index = knn.kneighbors(test_feature, return_distance=True)\n",
    "\n",
    "# Save the results\n",
    "np.save('./result/knn-triplet-inception-0.5-distance.npy', distance)\n",
    "np.save('./result/knn-triplet-inception-0.5-neighbor.npy', neighbor_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_distance = np.load('./result/knn-triplet-inception-0.5-distance.npy')\n",
    "knn_neighbor = np.load('./result/knn-triplet-inception-0.5-neighbor.npy')\n",
    "\n",
    "# Get the first 50 neighbors\n",
    "predictions = []\n",
    "for neighbors in knn_neighbor:\n",
    "    predictions.append(train_val_df.loc[neighbors]['landmark_id'].values)\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "np.save('./result/knn-triplet-inception-0.5-test-prediction.npy', predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top  1 accuracy:\t 0.33142780581483633\n",
      "Top  5 accuracy:\t 0.49636014470099593\n",
      "Top 10 accuracy:\t 0.5658076905899692\n",
      "Top 20 accuracy:\t 0.63672904291903\n"
     ]
    }
   ],
   "source": [
    "print('Top  1 accuracy:\\t', accuracy(test_df['landmark_id'].values, predictions, top=1))\n",
    "print('Top  5 accuracy:\\t', accuracy(test_df['landmark_id'].values, predictions, top=5))\n",
    "print('Top 10 accuracy:\\t', accuracy(test_df['landmark_id'].values, predictions, top=10))\n",
    "print('Top 20 accuracy:\\t', accuracy(test_df['landmark_id'].values, predictions, top=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_acc = []\n",
    "for i in range(1, 51):\n",
    "    tmp_acc = accuracy(test_df['landmark_id'].values, predictions, top=i)\n",
    "    knn_acc.append(tmp_acc)\n",
    "\n",
    "np.save('./result/knn-triplet-inception-0.5-accuracy.npy', knn_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
